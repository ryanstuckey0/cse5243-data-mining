{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSE 5243 - Introduction to Data Mining\n",
    "## Homework 2: Classification\n",
    "- Semester: Spring 2021\n",
    "- Instructor: Vedang Patel\n",
    "- Section: Tuesday/Thursday 9:35AM\n",
    "- Student Name: Ryan Stuckey\n",
    "- Student Email: stuckey.87@osu.edu\n",
    "- Student ID: 500201211\n",
    "\n",
    "Template Version V2.(Adopted from Prof. Tom Bihari's version)\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instructions and Helpful Hints:**\n",
    "- Consider putting all of your \"discussion\" text in markdown cells, not inline with code. That gives you more control over formatting. Markdown cheat sheet: https://www.markdownguide.org/cheat-sheet\n",
    "- Explain what you are doing, and why.  Explain what you found out or learned.\n",
    "- *Make sure you run your entire workbook before handing it in, so the output cells are populated.*\n",
    "- Follow the Section structure as much as possible - put your content where it is requested, so we can find your answers.\n",
    "- If you have questions on expectations or need clarification or guidance, please ask.  Post to Piazza if it is a general question, so everyone benefits.\n",
    "- The class label for this exercise is IsitDay."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Section: Overview\n",
    "- Insert a short description of the scope of this exercise, any supporting information, etc.\n",
    "***"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Section: Setup\n",
    "- Add any needed imports, helper functions, etc., here.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.pipeline import Pipeline\n",
    "from statistics import mean\n",
    "\n",
    "import pandas as pd\n",
    "import texttable as tt\n",
    "\n",
    "import hw2\n",
    "\n",
    "train_data = hw2.data('altered_seoulbikedata_train.csv')\n",
    "test_data = hw2.data('altered_seoulbikedata_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "***\n",
    "# Section: 1 - Evaluation Method\n",
    "- Define measures for evaluating the classification models you develop.  Explain why the measures you choose provide a useful view into the value and usefulness of the model you eventually chose for the company to use.  Define two types:\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Section: 1.1 - Define measures that do not include the cost information\n",
    "- (e.g., confusion matrices, accuracy, precision, recall, F-measures, etc.).\n",
    "***"
   ]
  },
  {
   "source": [
    "### Confusion Matrix\n",
    "- simple representation that shows number of true positives, false positives, true negatives, and false negatives\n",
    "- true positives and true negatives are the desired outcomes and we want these numbers to be maximized\n",
    "- used in a wide variety of different measures\n",
    "\n",
    "### Accuracy\n",
    "- just a ratio of the correct classifications to the total number of classifications\n",
    "- can be problematic and misleading in certain instances if a large amount of the data belongs to a single class\n",
    "\n",
    "### Precision\n",
    "- ratio over number of true positive classifications over the total number of predicted positive classifications (both true and false positives)\n",
    "- gives us a better idea of how well our model performed in identifying true positive cases (regardless of how much data belongs to either class) and how our model does at avoiding false positives\n",
    "\n",
    "### Recall/Sensitivity/True Positive Rate\n",
    "- similar to precision, but looks at actual positive classification instead\n",
    "- recall is a ratio of number of true positive classifications to total actual positive classifications\n",
    "\n",
    "### Specitivity/True Negative Rate\n",
    "- like recall, but looks at the actual negative classification\n",
    "- ratio of number of true negatives to total actual negative classifications\n",
    "\n",
    "### False Positive Rate\n",
    "- ratio of number of false positives over total number of true negatives and false positives\n",
    "- also just (1 - specitivity) or &#945;\n",
    "\n",
    "### False Negative Rate\n",
    "- ratio of number of false negatives over total number of false negatives and true positives\n",
    "- also just (1 - sensitivity) or &#946;\n",
    "\n",
    "### Power\n",
    "- same thing as recall/sensitivity\n",
    "\n",
    "### F-measure\n",
    "- combines precision and recall measure\n",
    "- calculate with (2\\*precision\\*recall)/(precision+recall)\n",
    "\n",
    "### Type I and Type II Errors\n",
    "- Type I error is an error in which we reject null hypothesis even though it is true (or a false positive)\n",
    "- &#945; is the probability that we have a Type I error\n",
    "- Type II error is where we accept a nyull hypothesis even though it is false (or a false negative)\n",
    "- &#946; is the probability that we have a Type II error\n",
    "\n",
    "### Scoring Choices\n",
    "To evaluate my models, I chose F-measure, accuracy, recall, and precision. I chose F-measure because I think it will provide a good overview of how well my model did. Accuracy was chosen because it is straight forward and easy to compute; even though it can be misleading, I still wanted to compute it to see what it was. I chose recall and precision because those will better let me know how good my model is doing at identifying positive case. Precision here is important, as that will tell us how good our model is doing at avoiding a positive label when the label is actually negative. If our model predicts a true value of IsitDay when it is actually false, then the bike's headlights would turn off at nighttime."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize list of evaluation methods to use later\n",
    "scoring=['accuracy', 'f1', 'precision', 'recall']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Section: 1.2 - Define measures that do include the cost information\n",
    "- (e.g., using cost matrices).\n",
    "***"
   ]
  },
  {
   "source": [
    "### Cost Matrix\n",
    "- just gives the cost of each potential outcome (i.e., true postive, false positive, true negative, false negative)\n",
    "- calculate total cost of model by multiplying each outcome by the cost for that outcome\n",
    "- can be used to emphasize that some classifications are extremely unfavorable compared to others\n",
    "- an example of this would be a self-driving care when it is stopped at a stop sign and deciding if a car is coming and it should wait\n",
    "    - true positive is when the car decides a car is coming and a car is actually coming, true negative is when car decides a car is not coming and a car is not actually coming\n",
    "    - in this case, a false negative would be very undesirable, as it could lead to a potential collision (e.g., car decides it is safe to move when a car is coming)\n",
    "    - to address this, we can give a high cost to false negatives while giving a low cost to false postive (i.e., better to wait than to risk a crash)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "***\n",
    "# Section: 2 - Pre-Processing of the Dataset\n",
    "- Use the altered_seoulbikedata_train.  Split it into a Training dataset and a validation dataset.  Keep them separate and use the Training dataset for training/tuning and the validation dataset for hyperparameter tuning. Or you can use cross validation - https://scikit-learn.org/stable/modules/cross_validation.html.\n",
    "***\n",
    "\n",
    "For my training and validation sets, I am going to use cross validation (CV) as mentioned above using SciKit Learn's [cross_val_score method](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score). This step is done later after instantiating my classfiers. \n",
    "\n",
    "With this method, you can fit the data using the given classifier, training set, and target set. In addition, you specify how many folds to use as well as the evaluation method to use from [this list](https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter). The method returns an array with the score for each run of CV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Section: 2.1 - Revise the dataset\n",
    "- Review the meanings of the attributes and consider removing redundant or (likely) irrelevant attributes, combining attributes, etc., to reduce the number of attributes.\n",
    "- (You may choose to use techniques such as those you used in Homework 1 to analyze the impacts of individual attributes on the CLASS attribute, but you need not do a “deep” analysis.)\n",
    "- Describe what you chose to do (and not do), and why.\n",
    "***\n",
    "\n",
    "### Transformations\n",
    "- For my initial revisions, I did applied the same transformations that I used in homework 1. My transformations involved removing outliers (using 1.5xIQR method) and removing and potentially erroneous data. These revisions included:\n",
    "    1. Identify and remove temperature outliers. For this, I took outliers in each day, as temperaure will widely vary throughout the year (e.g., temperatures in summer vs. temperatures in winter) but varies less throughout the day.\n",
    "    2. Identify and remove dew point outliers. Even though I am removing the dew point attribute (due to its low correlation with our class attribute, IsitDay), I want to remove outliers for it because I use it to check for erroneous humidity values in the next step.\n",
    "    3. Check for erroneous humidity outliers. To do this, I check if the recorded humidity is within a certain range of my calculate humidity. I calculate the humidity using the formula found in the function hw2.humidty in (hw2.py). If the acceptable humidity varies by &#177;5, then I will remove that data entry.\n",
    "    4. Finally, I remove any extra/irrelevant attributes. These are attributes I found to be uncessary in predicitng IsitDay. To determine if their relevance, I took their correlation with IsitDay and reasoned with logic on whether or not they were important. The attributes I ended up removing were Visibility, Dew point temperature, Rainfall, Snowfall, Seasons, Holiday, Functioning day, and Date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--Transformation Summary--\n",
      "+---------------------+-------+\n",
      "| Elimination Cause   | Count |\n",
      "+---------------------+-------+\n",
      "| Temperature Outlier | 270   |\n",
      "+---------------------+-------+\n",
      "| Humidity Error      | 78    |\n",
      "+---------------------+-------+\n",
      "| Total Eliminations  | 348   |\n",
      "+---------------------+-------+\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       Rented Bike Count  Temperature(C)  Humidity(%)  Wind speed (m/s)  \\\n",
       "count        7010.000000     7010.000000  7010.000000       7010.000000   \n",
       "mean          711.702282       12.894479    58.472896          1.716933   \n",
       "std           651.263850       11.904562    20.153850          1.035290   \n",
       "min             0.000000      -17.800000    11.000000          0.000000   \n",
       "25%           193.000000        3.500000    43.000000          0.900000   \n",
       "50%           509.000000       13.600000    57.000000          1.500000   \n",
       "75%          1074.000000       22.500000    74.000000          2.300000   \n",
       "max          3556.000000       39.400000    98.000000          7.400000   \n",
       "\n",
       "       Solar Radiation (MJ/m2)  \n",
       "count              7010.000000  \n",
       "mean                  0.567655  \n",
       "std                   0.866163  \n",
       "min                   0.000000  \n",
       "25%                   0.000000  \n",
       "50%                   0.010000  \n",
       "75%                   0.930000  \n",
       "max                   3.520000  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Rented Bike Count</th>\n      <th>Temperature(C)</th>\n      <th>Humidity(%)</th>\n      <th>Wind speed (m/s)</th>\n      <th>Solar Radiation (MJ/m2)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>7010.000000</td>\n      <td>7010.000000</td>\n      <td>7010.000000</td>\n      <td>7010.000000</td>\n      <td>7010.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>711.702282</td>\n      <td>12.894479</td>\n      <td>58.472896</td>\n      <td>1.716933</td>\n      <td>0.567655</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>651.263850</td>\n      <td>11.904562</td>\n      <td>20.153850</td>\n      <td>1.035290</td>\n      <td>0.866163</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>-17.800000</td>\n      <td>11.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>193.000000</td>\n      <td>3.500000</td>\n      <td>43.000000</td>\n      <td>0.900000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>509.000000</td>\n      <td>13.600000</td>\n      <td>57.000000</td>\n      <td>1.500000</td>\n      <td>0.010000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>1074.000000</td>\n      <td>22.500000</td>\n      <td>74.000000</td>\n      <td>2.300000</td>\n      <td>0.930000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>3556.000000</td>\n      <td>39.400000</td>\n      <td>98.000000</td>\n      <td>7.400000</td>\n      <td>3.520000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "print('--Transformation Summary--')\n",
    "target = hw2.hw1_transformation(train_data)\n",
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Section: 2.2 - Transform the attributes\n",
    "- Consider transforming the remaining attributes (e.g., one hot encoding in case python classification models does not support nomial attribute), normalizing / scaling values, encoding labels (if necessary), etc.\n",
    "- Describe what you chose to do (and not do), and why.\n",
    "***\n",
    "\n",
    "### Additional Transformations\n",
    "- The only additional transformation I found necessary was to normalize my data via SciKit's MinMaxScaler class.\n",
    "- With the attributes I had leftover, I did not need to do anything like one hot encoding or encoding of labels because all values I had leftover were numerical.\n",
    "\n",
    "The results from scaling can be seen below. Notice how all values now range from 0 to 1 in comparison to the data printed in Section 1.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       Rented Bike Count  Temperature(C)  Humidity(%)  Wind speed (m/s)  \\\n",
       "count        7010.000000     7010.000000  7010.000000       7010.000000   \n",
       "mean            0.200141        0.536617     0.545665          0.232018   \n",
       "std             0.183145        0.208122     0.231653          0.139904   \n",
       "min             0.000000        0.000000     0.000000          0.000000   \n",
       "25%             0.054274        0.372378     0.367816          0.121622   \n",
       "50%             0.143138        0.548951     0.528736          0.202703   \n",
       "75%             0.302025        0.704545     0.724138          0.310811   \n",
       "max             1.000000        1.000000     1.000000          1.000000   \n",
       "\n",
       "       Solar Radiation (MJ/m2)  \n",
       "count              7010.000000  \n",
       "mean                  0.161266  \n",
       "std                   0.246069  \n",
       "min                   0.000000  \n",
       "25%                   0.000000  \n",
       "50%                   0.002841  \n",
       "75%                   0.264205  \n",
       "max                   1.000000  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Rented Bike Count</th>\n      <th>Temperature(C)</th>\n      <th>Humidity(%)</th>\n      <th>Wind speed (m/s)</th>\n      <th>Solar Radiation (MJ/m2)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>7010.000000</td>\n      <td>7010.000000</td>\n      <td>7010.000000</td>\n      <td>7010.000000</td>\n      <td>7010.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.200141</td>\n      <td>0.536617</td>\n      <td>0.545665</td>\n      <td>0.232018</td>\n      <td>0.161266</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.183145</td>\n      <td>0.208122</td>\n      <td>0.231653</td>\n      <td>0.139904</td>\n      <td>0.246069</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.054274</td>\n      <td>0.372378</td>\n      <td>0.367816</td>\n      <td>0.121622</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.143138</td>\n      <td>0.548951</td>\n      <td>0.528736</td>\n      <td>0.202703</td>\n      <td>0.002841</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.302025</td>\n      <td>0.704545</td>\n      <td>0.724138</td>\n      <td>0.310811</td>\n      <td>0.264205</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train_data)\n",
    "train_data = pd.DataFrame(scaler.transform(train_data), columns=train_data.columns)\n",
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Section: 3 - Evaluation of the Off-The-Shelf KNN Classifier\n",
    "- Select the KNN classifier from the SciKit Learn library and run it on the dataset.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Section: 3.1 - Configure the off-the-shelf KNN classifier\n",
    "- Use the KNeighborsClassifier from the SciKit Learn library\n",
    "- Explain all setup, parameters and execution options you chose to set, and why.\n",
    "***\n",
    "\n",
    "The definition for SciKit's KNeighborsClassifier class is:\n",
    "\n",
    "```\n",
    "KNeighborsClassifier(n_neighbors=5, *, weights='uniform', algorithm='auto', leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=None, **kwargs)\n",
    "```\n",
    "\n",
    "The parameters that are important or that I'll be changing are described below:\n",
    "- n_neighbors- number of nearest neighbors to compute; default = 5\n",
    "- weights- weighting function to use when looking at points in neighborhood; default = 'uniform' but 'distance' or a user defined weighting function can also be passed\n",
    "- algorithm- algorithm used to compute nearest neighbors; default = 'auto' but other options include 'ball_tree', 'kd_tree', or 'brute'\n",
    "- metric- method to use for measuring distance; acceptable values can be found [here](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.DistanceMetric.html#sklearn.neighbors.DistanceMetric) or a user-defined function can be passed in; default = Minkowski, which has the formula sum(|x - y|^p)^(1/p)\n",
    "- p- power to use for computing Minkowski metric and refers to the *p* value in the formula above; p=1 is Manhattan distance and p=2 is Euclidean distance\n",
    "- metric_params- additionaly parameters for the metric formula passed in\n",
    "\n",
    "### KNN Instantiation\n",
    "For my KNN classifier, I am going to be trying 10 different classifiers, split into two groups. Group 1 will contain 5 classifiers, look for 1 to 5 nearest neighbors, and use Manhattan distance. Group 2 will also contain 5 classfiers, look for 1 to 5 nearest neighbors, and use Euclidean distance. \n",
    "\n",
    "I am not quite sure where to start when choosing my value for k, so I wanted to test a considerable range of values. If I make it too small, my classifier will be too sensitive to noise points. However, if I make it too big, my classifier may find data from other classes.\n",
    "\n",
    "Additionally, I'll be using cross validation with SciKit's cross_val_score and cross_validate methods to train and validate my model. cross_validate is just like cross_val_score, but it allows multiple types of evaluation measures to be used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_neighbors, max_neighbors = 1,5\n",
    "knn_manhat = [KNeighborsClassifier(n_neighbors=x, metric='manhattan') for x in range(min_neighbors, max_neighbors + 1)]\n",
    "knn_euclid = [KNeighborsClassifier(n_neighbors=x, metric='euclidean') for x in range(min_neighbors, max_neighbors + 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Section: 3.2 - Run and evaluate the classifier\n",
    "- Try several values of the K parameter and compare the results.\n",
    "- Evaluate the performance of the classifier, using the evaluation method you defined above.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+---------------------------+----------+-----------+--------+-----------+\n| Results for Manhattan KNN |          |           |        |           |\n+===========================+==========+===========+========+===========+\n| Value of K                | Accuracy | F-measure | Recall | Precision |\n+---------------------------+----------+-----------+--------+-----------+\n| k=1                       | 0.902    | 0.889     | 0.859  | 0.922     |\n+---------------------------+----------+-----------+--------+-----------+\n| k=2                       | 0.897    | 0.876     | 0.795  | 0.976     |\n+---------------------------+----------+-----------+--------+-----------+\n| k=3                       | 0.916    | 0.902     | 0.852  | 0.959     |\n+---------------------------+----------+-----------+--------+-----------+\n| k=4                       | 0.904    | 0.886     | 0.812  | 0.975     |\n+---------------------------+----------+-----------+--------+-----------+\n| k=5                       | 0.915    | 0.901     | 0.842  | 0.970     |\n+---------------------------+----------+-----------+--------+-----------+\n+---------------------------+----------+-----------+--------+-----------+\n| Results for Euclidean KNN |          |           |        |           |\n+===========================+==========+===========+========+===========+\n| Value of K                | Accuracy | F-measure | Recall | Precision |\n+---------------------------+----------+-----------+--------+-----------+\n| k=1                       | 0.899    | 0.888     | 0.869  | 0.908     |\n+---------------------------+----------+-----------+--------+-----------+\n| k=2                       | 0.903    | 0.885     | 0.810  | 0.975     |\n+---------------------------+----------+-----------+--------+-----------+\n| k=3                       | 0.915    | 0.903     | 0.858  | 0.953     |\n+---------------------------+----------+-----------+--------+-----------+\n| k=4                       | 0.907    | 0.890     | 0.819  | 0.974     |\n+---------------------------+----------+-----------+--------+-----------+\n| k=5                       | 0.914    | 0.900     | 0.847  | 0.960     |\n+---------------------------+----------+-----------+--------+-----------+\n"
     ]
    }
   ],
   "source": [
    "knn_manhat_scores = [cross_validate(estimator=knn_manhat[i], X=train_data, y=target, cv=5, scoring=scoring) for i in range(0, len(knn_manhat))]\n",
    "knn_euclid_scores = [cross_validate(estimator=knn_euclid[i], X=train_data, y=target, cv=5, scoring=scoring) for i in range(0, len(knn_euclid))]\n",
    "\n",
    "table = tt.Texttable()\n",
    "table.add_rows([['Results for Manhattan KNN', '', '', '', ''],\n",
    "                ['Value of K', 'Accuracy', 'F-measure', 'Recall', 'Precision']\n",
    "])\n",
    "\n",
    "for i in range(0, len(knn_manhat_scores)):\n",
    "    table.add_row( ['k=' + str(i+1), mean(knn_manhat_scores[i]['test_accuracy']), mean(knn_manhat_scores[i]['test_f1']), mean(knn_manhat_scores[i]['test_recall']), mean(knn_manhat_scores[i]['test_precision']) ])\n",
    "print(table.draw())\n",
    "\n",
    "table = tt.Texttable()\n",
    "table.add_rows([['Results for Euclidean KNN', '', '', '', ''],\n",
    "                ['Value of K', 'Accuracy', 'F-measure', 'Recall', 'Precision']\n",
    "])\n",
    "for i in range(0, len(knn_euclid_scores)):\n",
    "    table.add_row( ['k=' + str(i+1), mean(knn_euclid_scores[i]['test_accuracy']), mean(knn_euclid_scores[i]['test_f1']), mean(knn_euclid_scores[i]['test_recall']), mean(knn_euclid_scores[i]['test_precision']) ])\n",
    "print(table.draw())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Section: 3.3 - Evaluate the choice of the KNN classifier\n",
    "- What characteristics of the problem and data made KNN a good or bad choice?\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Overall, my KNN classsifier produced excellent results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Section: 4 - Evaluation of Off-The-Shelf Classifier #2\n",
    "- As with the KNN classifier above, choose another classifier from the SciKit Learn library (Decision Tree, SVM, Logistic Regression, etc.) and run it on the dataset.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Section: 4.1 - Configure the classifier\n",
    "- Use the appropriate classifier from the SciKit Learn library.\n",
    "- Explain all setup, parameters and execution options you chose to set, and why.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Section: 4.2 - Run and evaluate the classifier\n",
    "- Try several values of the parameters (if appropriate) and compare the results.\n",
    "- Evaluate the performance of the classifier, using the evaluation method you defined above.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Section: 4.3 - Evaluate the choice of the classifier\n",
    "- What characteristics of the problem and data made the classifier a good or bad choice?\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Section: 5 - Evaluation of Off-The-Shelf Classifier #3\n",
    "- As with the KNN classifier above, choose another classifier from the SciKit Learn library (Decision Tree, SVM, Logistic Regression, etc.) and run it on the dataset.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Section: 5.1 - Configure the classifier\n",
    "- Use the appropriate classifier from the SciKit Learn library.\n",
    "- Explain all setup, parameters and execution options you chose to set, and why.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Section: 5.2 - Run and evaluate the classifier\n",
    "- Try several values of the parameters (if appropriate) and compare the results.\n",
    "- Evaluate the performance of the classifier, using the evaluation method you defined above.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Section: 5.3 - Evaluate the choice of the classifier\n",
    "- What characteristics of the problem and data made the classifier a good or bad choice?\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Section: 6 - Comparison of the Three Classifiers\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Section: 6.1 - Compare the performance of these classifiers to each other\n",
    "- What are their strong and weak points?Configure the classifier\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Section: 6.2 - Choose a Best Classifier\n",
    "- Choose one of the three classifiers as best and explain why.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Section: 7 - Conclusions\n",
    "- Write a paragraph on what you discovered or learned from this homework.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### END-OF-SUBMISSION\n",
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.2 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "ac2eaa0ea0ebeafcc7822e65e46aa9d4f966f30b695406963e145ea4a91cd4fc"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2-final"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}